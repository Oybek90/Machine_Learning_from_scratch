{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "class RBM:\n",
    "  \n",
    "  def __init__(self, num_visible, num_hidden):\n",
    "    self.num_hidden = num_hidden\n",
    "    self.num_visible = num_visible\n",
    "    self.debug_print = True\n",
    "\n",
    "    # Initialize a weight matrix, of dimensions (num_visible x num_hidden), using\n",
    "    # a uniform distribution between -sqrt(6. / (num_hidden + num_visible))\n",
    "    # and sqrt(6. / (num_hidden + num_visible)). One could vary the \n",
    "    # standard deviation by multiplying the interval with appropriate value.\n",
    "    # Here we initialize the weights with mean 0 and standard deviation 0.1. \n",
    "    # Reference: Understanding the difficulty of training deep feedforward \n",
    "    # neural networks by Xavier Glorot and Yoshua Bengio\n",
    "    np_rng = np.random.RandomState(1234)\n",
    "\n",
    "    self.weights = np.asarray(np_rng.uniform(\n",
    "\t\t\tlow=-0.1 * np.sqrt(6. / (num_hidden + num_visible)),\n",
    "                       \thigh=0.1 * np.sqrt(6. / (num_hidden + num_visible)),\n",
    "                       \tsize=(num_visible, num_hidden)))\n",
    "\n",
    "\n",
    "    # Insert weights for the bias units into the first row and first column.\n",
    "    self.weights = np.insert(self.weights, 0, 0, axis = 0)\n",
    "    self.weights = np.insert(self.weights, 0, 0, axis = 1)\n",
    "\n",
    "  def train(self, data, max_epochs = 1000, learning_rate = 0.1):\n",
    "    \"\"\"\n",
    "    Train the machine.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: A matrix where each row is a training example consisting of the states of visible units.    \n",
    "    \"\"\"\n",
    "\n",
    "    num_examples = data.shape[0]\n",
    "\n",
    "    # Insert bias units of 1 into the first column.\n",
    "    data = np.insert(data, 0, 1, axis = 1)\n",
    "\n",
    "    for epoch in range(max_epochs):      \n",
    "      # Clamp to the data and sample from the hidden units. \n",
    "      # (This is the \"positive CD phase\", aka the reality phase.)\n",
    "      pos_hidden_activations = np.dot(data, self.weights)      \n",
    "      pos_hidden_probs = self._logistic(pos_hidden_activations)\n",
    "      pos_hidden_probs[:,0] = 1 # Fix the bias unit.\n",
    "      pos_hidden_states = pos_hidden_probs > np.random.rand(num_examples, self.num_hidden + 1)\n",
    "      # Note that we're using the activation *probabilities* of the hidden states, not the hidden states       \n",
    "      # themselves, when computing associations. We could also use the states; see section 3 of Hinton's \n",
    "      # \"A Practical Guide to Training Restricted Boltzmann Machines\" for more.\n",
    "      pos_associations = np.dot(data.T, pos_hidden_probs)\n",
    "\n",
    "      # Reconstruct the visible units and sample again from the hidden units.\n",
    "      # (This is the \"negative CD phase\", aka the daydreaming phase.)\n",
    "      neg_visible_activations = np.dot(pos_hidden_states, self.weights.T)\n",
    "      neg_visible_probs = self._logistic(neg_visible_activations)\n",
    "      neg_visible_probs[:,0] = 1 # Fix the bias unit.\n",
    "      neg_hidden_activations = np.dot(neg_visible_probs, self.weights)\n",
    "      neg_hidden_probs = self._logistic(neg_hidden_activations)\n",
    "      # Note, again, that we're using the activation *probabilities* when computing associations, not the states \n",
    "      # themselves.\n",
    "      neg_associations = np.dot(neg_visible_probs.T, neg_hidden_probs)\n",
    "\n",
    "      # Update weights.\n",
    "      self.weights += learning_rate * ((pos_associations - neg_associations) / num_examples)\n",
    "\n",
    "      error = np.sum((data - neg_visible_probs) ** 2)\n",
    "      if self.debug_print:\n",
    "        print(\"Epoch %s: error is %s\" % (epoch, error))\n",
    "\n",
    "  def run_visible(self, data):\n",
    "    \"\"\"\n",
    "    Assuming the RBM has been trained (so that weights for the network have been learned),\n",
    "    run the network on a set of visible units, to get a sample of the hidden units.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: A matrix where each row consists of the states of the visible units.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    hidden_states: A matrix where each row consists of the hidden units activated from the visible\n",
    "    units in the data matrix passed in.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_examples = data.shape[0]\n",
    "    \n",
    "    # Create a matrix, where each row is to be the hidden units (plus a bias unit)\n",
    "    # sampled from a training example.\n",
    "    hidden_states = np.ones((num_examples, self.num_hidden + 1))\n",
    "    \n",
    "    # Insert bias units of 1 into the first column of data.\n",
    "    data = np.insert(data, 0, 1, axis = 1)\n",
    "\n",
    "    # Calculate the activations of the hidden units.\n",
    "    hidden_activations = np.dot(data, self.weights)\n",
    "    # Calculate the probabilities of turning the hidden units on.\n",
    "    hidden_probs = self._logistic(hidden_activations)\n",
    "    # Turn the hidden units on with their specified probabilities.\n",
    "    hidden_states[:,:] = hidden_probs > np.random.rand(num_examples, self.num_hidden + 1)\n",
    "    # Always fix the bias unit to 1.\n",
    "    # hidden_states[:,0] = 1\n",
    "  \n",
    "    # Ignore the bias units.\n",
    "    hidden_states = hidden_states[:,1:]\n",
    "    return hidden_states\n",
    "    \n",
    "  # TODO: Remove the code duplication between this method and `run_visible`?\n",
    "  def run_hidden(self, data):\n",
    "    \"\"\"\n",
    "    Assuming the RBM has been trained (so that weights for the network have been learned),\n",
    "    run the network on a set of hidden units, to get a sample of the visible units.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: A matrix where each row consists of the states of the hidden units.\n",
    "    Returns\n",
    "    -------\n",
    "    visible_states: A matrix where each row consists of the visible units activated from the hidden\n",
    "    units in the data matrix passed in.\n",
    "    \"\"\"\n",
    "\n",
    "    num_examples = data.shape[0]\n",
    "\n",
    "    # Create a matrix, where each row is to be the visible units (plus a bias unit)\n",
    "    # sampled from a training example.\n",
    "    visible_states = np.ones((num_examples, self.num_visible + 1))\n",
    "\n",
    "    # Insert bias units of 1 into the first column of data.\n",
    "    data = np.insert(data, 0, 1, axis = 1)\n",
    "\n",
    "    # Calculate the activations of the visible units.\n",
    "    visible_activations = np.dot(data, self.weights.T)\n",
    "    # Calculate the probabilities of turning the visible units on.\n",
    "    visible_probs = self._logistic(visible_activations)\n",
    "    # Turn the visible units on with their specified probabilities.\n",
    "    visible_states[:,:] = visible_probs > np.random.rand(num_examples, self.num_visible + 1)\n",
    "    # Always fix the bias unit to 1.\n",
    "    # visible_states[:,0] = 1\n",
    "\n",
    "    # Ignore the bias units.\n",
    "    visible_states = visible_states[:,1:]\n",
    "    return visible_states\n",
    "    \n",
    "  def daydream(self, num_samples):\n",
    "    \"\"\"\n",
    "    Randomly initialize the visible units once, and start running alternating Gibbs sampling steps\n",
    "    (where each step consists of updating all the hidden units, and then updating all of the visible units),\n",
    "    taking a sample of the visible units at each step.\n",
    "    Note that we only initialize the network *once*, so these samples are correlated.\n",
    "    Returns\n",
    "    -------\n",
    "    samples: A matrix, where each row is a sample of the visible units produced while the network was\n",
    "    daydreaming.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a matrix, where each row is to be a sample of of the visible units \n",
    "    # (with an extra bias unit), initialized to all ones.\n",
    "    samples = np.ones((num_samples, self.num_visible + 1))\n",
    "\n",
    "    # Take the first sample from a uniform distribution.\n",
    "    samples[0,1:] = np.random.rand(self.num_visible)\n",
    "\n",
    "    # Start the alternating Gibbs sampling.\n",
    "    # Note that we keep the hidden units binary states, but leave the\n",
    "    # visible units as real probabilities. See section 3 of Hinton's\n",
    "    # \"A Practical Guide to Training Restricted Boltzmann Machines\"\n",
    "    # for more on why.\n",
    "    for i in range(1, num_samples):\n",
    "      visible = samples[i-1,:]\n",
    "\n",
    "      # Calculate the activations of the hidden units.\n",
    "      hidden_activations = np.dot(visible, self.weights)      \n",
    "      # Calculate the probabilities of turning the hidden units on.\n",
    "      hidden_probs = self._logistic(hidden_activations)\n",
    "      # Turn the hidden units on with their specified probabilities.\n",
    "      hidden_states = hidden_probs > np.random.rand(self.num_hidden + 1)\n",
    "      # Always fix the bias unit to 1.\n",
    "      hidden_states[0] = 1\n",
    "\n",
    "      # Recalculate the probabilities that the visible units are on.\n",
    "      visible_activations = np.dot(hidden_states, self.weights.T)\n",
    "      visible_probs = self._logistic(visible_activations)\n",
    "      visible_states = visible_probs > np.random.rand(self.num_visible + 1)\n",
    "      samples[i,:] = visible_states\n",
    "\n",
    "    # Ignore the bias units (the first column), since they're always set to 1.\n",
    "    return samples[:,1:]        \n",
    "      \n",
    "  def _logistic(self, x):\n",
    "    return 1.0 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: error is 8.962370747522094\n",
      "Epoch 1: error is 8.812694381341267\n",
      "Epoch 2: error is 8.564781266332906\n",
      "Epoch 3: error is 8.430312629235921\n",
      "Epoch 4: error is 8.274050467090897\n",
      "Epoch 5: error is 8.176756190659537\n",
      "Epoch 6: error is 7.765723696993041\n",
      "Epoch 7: error is 7.76083505803827\n",
      "Epoch 8: error is 7.64549825154297\n",
      "Epoch 9: error is 7.44077797415636\n",
      "Epoch 10: error is 7.365906761346369\n",
      "Epoch 11: error is 7.11002419091621\n",
      "Epoch 12: error is 7.17340760640879\n",
      "Epoch 13: error is 7.2071269058926255\n",
      "Epoch 14: error is 7.106031079069116\n",
      "Epoch 15: error is 6.893418112829912\n",
      "Epoch 16: error is 7.1484255453897285\n",
      "Epoch 17: error is 6.585174766943467\n",
      "Epoch 18: error is 6.540648158897361\n",
      "Epoch 19: error is 6.521497538210716\n",
      "Epoch 20: error is 6.431275331073884\n",
      "Epoch 21: error is 6.667387374017107\n",
      "Epoch 22: error is 6.383456039458962\n",
      "Epoch 23: error is 6.237361918392377\n",
      "Epoch 24: error is 6.734955753002318\n",
      "Epoch 25: error is 6.471893097740026\n",
      "Epoch 26: error is 6.403102348943233\n",
      "Epoch 27: error is 6.479807796401907\n",
      "Epoch 28: error is 6.360390969039761\n",
      "Epoch 29: error is 6.287750621536165\n",
      "Epoch 30: error is 6.078989339955019\n",
      "Epoch 31: error is 6.311798818849955\n",
      "Epoch 32: error is 5.958101673266111\n",
      "Epoch 33: error is 6.04075452610922\n",
      "Epoch 34: error is 6.220237712873898\n",
      "Epoch 35: error is 6.115369685152669\n",
      "Epoch 36: error is 6.174588953459389\n",
      "Epoch 37: error is 5.8450539878347465\n",
      "Epoch 38: error is 5.936980979545218\n",
      "Epoch 39: error is 5.887849137398054\n",
      "Epoch 40: error is 5.840571680208362\n",
      "Epoch 41: error is 6.087832785393588\n",
      "Epoch 42: error is 5.974482457157953\n",
      "Epoch 43: error is 6.181308550595477\n",
      "Epoch 44: error is 5.993078894215493\n",
      "Epoch 45: error is 5.90812755415677\n",
      "Epoch 46: error is 5.888460138703246\n",
      "Epoch 47: error is 5.794785212217763\n",
      "Epoch 48: error is 5.742882369298243\n",
      "Epoch 49: error is 5.695593587041203\n",
      "Epoch 50: error is 5.993578954801252\n",
      "Epoch 51: error is 5.7125668896611925\n",
      "Epoch 52: error is 5.864256131402064\n",
      "Epoch 53: error is 5.730984968418323\n",
      "Epoch 54: error is 5.711031311529695\n",
      "Epoch 55: error is 6.0300944025695795\n",
      "Epoch 56: error is 5.915126268169319\n",
      "Epoch 57: error is 5.8457048119795605\n",
      "Epoch 58: error is 5.777123228764637\n",
      "Epoch 59: error is 5.870339163896152\n",
      "Epoch 60: error is 5.9344328985477475\n",
      "Epoch 61: error is 5.857909710848552\n",
      "Epoch 62: error is 6.084361230656998\n",
      "Epoch 63: error is 5.875331528562727\n",
      "Epoch 64: error is 5.795041096721018\n",
      "Epoch 65: error is 5.749147297027243\n",
      "Epoch 66: error is 5.701384590810366\n",
      "Epoch 67: error is 5.823840228898706\n",
      "Epoch 68: error is 5.763013750677477\n",
      "Epoch 69: error is 5.604864994884713\n",
      "Epoch 70: error is 5.829454294544695\n",
      "Epoch 71: error is 5.807735103377685\n",
      "Epoch 72: error is 5.851367681785124\n",
      "Epoch 73: error is 5.6747565243593865\n",
      "Epoch 74: error is 5.70452535547747\n",
      "Epoch 75: error is 5.867470554711422\n",
      "Epoch 76: error is 5.88209988457329\n",
      "Epoch 77: error is 5.637507184117661\n",
      "Epoch 78: error is 5.6854547247354725\n",
      "Epoch 79: error is 5.666797580450598\n",
      "Epoch 80: error is 5.851144600476363\n",
      "Epoch 81: error is 5.743155373906399\n",
      "Epoch 82: error is 5.654272304720122\n",
      "Epoch 83: error is 5.959497755978547\n",
      "Epoch 84: error is 5.982717024264799\n",
      "Epoch 85: error is 5.652230379078639\n",
      "Epoch 86: error is 5.578521802526671\n",
      "Epoch 87: error is 5.742890676023682\n",
      "Epoch 88: error is 5.628479105255954\n",
      "Epoch 89: error is 5.910355660082931\n",
      "Epoch 90: error is 5.588280814718465\n",
      "Epoch 91: error is 5.8001302228590985\n",
      "Epoch 92: error is 5.726281459263061\n",
      "Epoch 93: error is 5.728680753651997\n",
      "Epoch 94: error is 5.8639722903108344\n",
      "Epoch 95: error is 5.616790124109929\n",
      "Epoch 96: error is 5.697769338776745\n",
      "Epoch 97: error is 5.732322028576369\n",
      "Epoch 98: error is 5.53824119670414\n",
      "Epoch 99: error is 5.775701625119379\n",
      "Epoch 100: error is 5.670018206122633\n",
      "Epoch 101: error is 5.759693484819946\n",
      "Epoch 102: error is 5.784524405066324\n",
      "Epoch 103: error is 5.753188529494956\n",
      "Epoch 104: error is 5.712937170908236\n",
      "Epoch 105: error is 5.780829085075552\n",
      "Epoch 106: error is 5.582989041823344\n",
      "Epoch 107: error is 5.660022123418723\n",
      "Epoch 108: error is 5.911532212821437\n",
      "Epoch 109: error is 5.714441656464148\n",
      "Epoch 110: error is 5.611489959445993\n",
      "Epoch 111: error is 5.693427733374782\n",
      "Epoch 112: error is 5.553323557393818\n",
      "Epoch 113: error is 5.678220432710625\n",
      "Epoch 114: error is 5.5479258618693805\n",
      "Epoch 115: error is 5.71648760816249\n",
      "Epoch 116: error is 5.832148541091993\n",
      "Epoch 117: error is 5.465369754883617\n",
      "Epoch 118: error is 5.706958185356759\n",
      "Epoch 119: error is 5.986722940079194\n",
      "Epoch 120: error is 5.595552126454319\n",
      "Epoch 121: error is 5.5253948959054755\n",
      "Epoch 122: error is 5.568957327100926\n",
      "Epoch 123: error is 5.859302785019491\n",
      "Epoch 124: error is 5.682240706760606\n",
      "Epoch 125: error is 5.647869908669284\n",
      "Epoch 126: error is 5.4866339959110615\n",
      "Epoch 127: error is 5.792431237033789\n",
      "Epoch 128: error is 5.502241455998374\n",
      "Epoch 129: error is 5.703842802109403\n",
      "Epoch 130: error is 5.597923383616028\n",
      "Epoch 131: error is 5.526998042890242\n",
      "Epoch 132: error is 5.6032526766286095\n",
      "Epoch 133: error is 5.6779401073144244\n",
      "Epoch 134: error is 5.700955941856339\n",
      "Epoch 135: error is 5.929204224481069\n",
      "Epoch 136: error is 5.9897282632123545\n",
      "Epoch 137: error is 5.6538819221893535\n",
      "Epoch 138: error is 5.668579522826625\n",
      "Epoch 139: error is 5.589781494006255\n",
      "Epoch 140: error is 5.816251039343751\n",
      "Epoch 141: error is 5.68229379051899\n",
      "Epoch 142: error is 5.627678913037521\n",
      "Epoch 143: error is 5.572967042413079\n",
      "Epoch 144: error is 5.833176178307499\n",
      "Epoch 145: error is 5.680328964240483\n",
      "Epoch 146: error is 5.569519391702535\n",
      "Epoch 147: error is 5.840037120473577\n",
      "Epoch 148: error is 5.680648187631908\n",
      "Epoch 149: error is 5.680985812403214\n",
      "Epoch 150: error is 5.7520590756320065\n",
      "Epoch 151: error is 5.835218094393141\n",
      "Epoch 152: error is 5.793802289243888\n",
      "Epoch 153: error is 6.032245506879831\n",
      "Epoch 154: error is 5.716001676584347\n",
      "Epoch 155: error is 5.570243438425454\n",
      "Epoch 156: error is 5.693240348345474\n",
      "Epoch 157: error is 5.471375476398069\n",
      "Epoch 158: error is 5.715721576949704\n",
      "Epoch 159: error is 5.340149837142051\n",
      "Epoch 160: error is 5.626151309103371\n",
      "Epoch 161: error is 5.660780413959158\n",
      "Epoch 162: error is 5.784276928007049\n",
      "Epoch 163: error is 5.847481222600297\n",
      "Epoch 164: error is 5.620868183692415\n",
      "Epoch 165: error is 5.6822877653744\n",
      "Epoch 166: error is 5.9603542497207105\n",
      "Epoch 167: error is 5.664424578588112\n",
      "Epoch 168: error is 5.610326942550534\n",
      "Epoch 169: error is 5.608965354147557\n",
      "Epoch 170: error is 5.4475698260081655\n",
      "Epoch 171: error is 5.585682290295183\n",
      "Epoch 172: error is 5.607970833877294\n",
      "Epoch 173: error is 5.6888486974429515\n",
      "Epoch 174: error is 5.738123791576599\n",
      "Epoch 175: error is 5.669054618651601\n",
      "Epoch 176: error is 5.669763811215596\n",
      "Epoch 177: error is 5.433751889935955\n",
      "Epoch 178: error is 5.918975666647143\n",
      "Epoch 179: error is 5.9405290238768425\n",
      "Epoch 180: error is 5.42714731465296\n",
      "Epoch 181: error is 6.072518695059343\n",
      "Epoch 182: error is 5.4963278579396055\n",
      "Epoch 183: error is 5.420705108752592\n",
      "Epoch 184: error is 5.588770400236718\n",
      "Epoch 185: error is 5.55857199792278\n",
      "Epoch 186: error is 5.681584022989664\n",
      "Epoch 187: error is 5.68140110167539\n",
      "Epoch 188: error is 5.680421191870695\n",
      "Epoch 189: error is 5.4355560118787825\n",
      "Epoch 190: error is 5.822733543061394\n",
      "Epoch 191: error is 5.549511384566333\n",
      "Epoch 192: error is 6.115368722154949\n",
      "Epoch 193: error is 5.574270866766911\n",
      "Epoch 194: error is 5.936295493254822\n",
      "Epoch 195: error is 5.721583773526243\n",
      "Epoch 196: error is 5.811998466738973\n",
      "Epoch 197: error is 5.68680875832871\n",
      "Epoch 198: error is 5.497732175437226\n",
      "Epoch 199: error is 5.221582302595252\n",
      "Epoch 200: error is 5.613422883262021\n",
      "Epoch 201: error is 5.6264111887142505\n",
      "Epoch 202: error is 5.59426008084287\n",
      "Epoch 203: error is 5.584880312558075\n",
      "Epoch 204: error is 5.594381862251564\n",
      "Epoch 205: error is 5.8130839499707925\n",
      "Epoch 206: error is 5.814573506013265\n",
      "Epoch 207: error is 5.830060512336067\n",
      "Epoch 208: error is 6.030613454849685\n",
      "Epoch 209: error is 5.206149716789961\n",
      "Epoch 210: error is 5.656487155761786\n",
      "Epoch 211: error is 5.598131729148925\n",
      "Epoch 212: error is 5.999394408526327\n",
      "Epoch 213: error is 5.34426722529202\n",
      "Epoch 214: error is 5.708185915310949\n",
      "Epoch 215: error is 5.68570592975047\n",
      "Epoch 216: error is 5.59833247157169\n",
      "Epoch 217: error is 5.853551567890944\n",
      "Epoch 218: error is 5.521557009292805\n",
      "Epoch 219: error is 5.5172645817696635\n",
      "Epoch 220: error is 5.0816972188493095\n",
      "Epoch 221: error is 5.441059946458223\n",
      "Epoch 222: error is 5.508618304094761\n",
      "Epoch 223: error is 5.683321654445352\n",
      "Epoch 224: error is 5.7881621165257675\n",
      "Epoch 225: error is 5.768401211628114\n",
      "Epoch 226: error is 5.048722762556764\n",
      "Epoch 227: error is 5.299324862197448\n",
      "Epoch 228: error is 5.425050857968868\n",
      "Epoch 229: error is 5.292398588892406\n",
      "Epoch 230: error is 5.729130611395918\n",
      "Epoch 231: error is 5.748109013664137\n",
      "Epoch 232: error is 5.83881584978217\n",
      "Epoch 233: error is 5.839401935593709\n",
      "Epoch 234: error is 5.819293184346097\n",
      "Epoch 235: error is 5.180004111181618\n",
      "Epoch 236: error is 5.516465724002701\n",
      "Epoch 237: error is 5.684286704700107\n",
      "Epoch 238: error is 5.603459892827612\n",
      "Epoch 239: error is 5.683391372338601\n",
      "Epoch 240: error is 5.951923521811166\n",
      "Epoch 241: error is 6.1706136957374165\n",
      "Epoch 242: error is 5.893198556624782\n",
      "Epoch 243: error is 5.75267036818613\n",
      "Epoch 244: error is 5.389810644838694\n",
      "Epoch 245: error is 5.590339598007124\n",
      "Epoch 246: error is 5.758649223610337\n",
      "Epoch 247: error is 5.682148981610083\n",
      "Epoch 248: error is 5.6006100639274\n",
      "Epoch 249: error is 5.69407827540203\n",
      "Epoch 250: error is 6.138217869760514\n",
      "Epoch 251: error is 5.51070021164025\n",
      "Epoch 252: error is 5.371577257004367\n",
      "Epoch 253: error is 5.672190528376129\n",
      "Epoch 254: error is 5.505299697255709\n",
      "Epoch 255: error is 5.6120349285034\n",
      "Epoch 256: error is 6.121250952269615\n",
      "Epoch 257: error is 5.80232254847776\n",
      "Epoch 258: error is 5.024737596811604\n",
      "Epoch 259: error is 5.4664819776033235\n",
      "Epoch 260: error is 5.517673173755935\n",
      "Epoch 261: error is 5.683896096316457\n",
      "Epoch 262: error is 5.3476963161775055\n",
      "Epoch 263: error is 5.9380398814619015\n",
      "Epoch 264: error is 4.795021235863952\n",
      "Epoch 265: error is 5.370606765215474\n",
      "Epoch 266: error is 5.169997844701789\n",
      "Epoch 267: error is 5.504953073726857\n",
      "Epoch 268: error is 5.156277350312808\n",
      "Epoch 269: error is 5.954239512024102\n",
      "Epoch 270: error is 6.100775321118922\n",
      "Epoch 271: error is 4.877731342054143\n",
      "Epoch 272: error is 5.906387826083562\n",
      "Epoch 273: error is 5.0190592207285505\n",
      "Epoch 274: error is 5.4617060170846345\n",
      "Epoch 275: error is 5.5843329088998255\n",
      "Epoch 276: error is 5.839038967833387\n",
      "Epoch 277: error is 6.064922701653414\n",
      "Epoch 278: error is 5.4576150337111375\n",
      "Epoch 279: error is 5.848459834154605\n",
      "Epoch 280: error is 5.8574477813414845\n",
      "Epoch 281: error is 5.690744999197452\n",
      "Epoch 282: error is 5.618871661572856\n",
      "Epoch 283: error is 5.998536694420541\n",
      "Epoch 284: error is 5.447688391458001\n",
      "Epoch 285: error is 5.268914041258877\n",
      "Epoch 286: error is 4.965370716795328\n",
      "Epoch 287: error is 6.080903910428319\n",
      "Epoch 288: error is 5.983974304010295\n",
      "Epoch 289: error is 5.192035095091039\n",
      "Epoch 290: error is 5.630527136802028\n",
      "Epoch 291: error is 4.717606840920977\n",
      "Epoch 292: error is 5.185693431036362\n",
      "Epoch 293: error is 4.443608216670881\n",
      "Epoch 294: error is 5.7954226793684525\n",
      "Epoch 295: error is 5.439362216717516\n",
      "Epoch 296: error is 5.35787201595351\n",
      "Epoch 297: error is 5.554886163090022\n",
      "Epoch 298: error is 5.222775196135898\n",
      "Epoch 299: error is 4.512080450189407\n",
      "Epoch 300: error is 4.429221775018464\n",
      "Epoch 301: error is 4.856843495474848\n",
      "Epoch 302: error is 5.427370110361398\n",
      "Epoch 303: error is 4.843174727741718\n",
      "Epoch 304: error is 4.380703657991176\n",
      "Epoch 305: error is 4.897543395472926\n",
      "Epoch 306: error is 4.664121357299077\n",
      "Epoch 307: error is 5.18482462174992\n",
      "Epoch 308: error is 5.666968267507691\n",
      "Epoch 309: error is 5.668077363007206\n",
      "Epoch 310: error is 5.611308229473274\n",
      "Epoch 311: error is 4.781907881307753\n",
      "Epoch 312: error is 5.722981212005781\n",
      "Epoch 313: error is 5.140783859425173\n",
      "Epoch 314: error is 4.725837168374687\n",
      "Epoch 315: error is 5.719293435177649\n",
      "Epoch 316: error is 5.061631864908465\n",
      "Epoch 317: error is 4.68066046721686\n",
      "Epoch 318: error is 5.301972174712979\n",
      "Epoch 319: error is 4.774247897716227\n",
      "Epoch 320: error is 5.650852744103781\n",
      "Epoch 321: error is 4.40008946096898\n",
      "Epoch 322: error is 5.182059663520191\n",
      "Epoch 323: error is 4.972183691774525\n",
      "Epoch 324: error is 5.899363120490519\n",
      "Epoch 325: error is 4.94841894172154\n",
      "Epoch 326: error is 5.028093854965741\n",
      "Epoch 327: error is 5.221620366324401\n",
      "Epoch 328: error is 4.031940734615779\n",
      "Epoch 329: error is 3.9152514190638272\n",
      "Epoch 330: error is 4.365982053822137\n",
      "Epoch 331: error is 5.068043907021381\n",
      "Epoch 332: error is 4.663144538679714\n",
      "Epoch 333: error is 4.90460718696106\n",
      "Epoch 334: error is 5.046648937664023\n",
      "Epoch 335: error is 3.513444014625698\n",
      "Epoch 336: error is 4.281481352148078\n",
      "Epoch 337: error is 4.310608979332466\n",
      "Epoch 338: error is 5.158182587465896\n",
      "Epoch 339: error is 4.428935156962825\n",
      "Epoch 340: error is 3.8349233041667294\n",
      "Epoch 341: error is 5.040917308120028\n",
      "Epoch 342: error is 5.180932356709087\n",
      "Epoch 343: error is 4.020879826733103\n",
      "Epoch 344: error is 3.1162606123869865\n",
      "Epoch 345: error is 3.544606591889711\n",
      "Epoch 346: error is 4.563250137199822\n",
      "Epoch 347: error is 3.7188036439979753\n",
      "Epoch 348: error is 4.311551722761425\n",
      "Epoch 349: error is 3.4400096705517345\n",
      "Epoch 350: error is 3.6709449982732543\n",
      "Epoch 351: error is 4.587297445887961\n",
      "Epoch 352: error is 3.6378111702542335\n",
      "Epoch 353: error is 2.9089983599263927\n",
      "Epoch 354: error is 4.178855709907653\n",
      "Epoch 355: error is 3.979848714832915\n",
      "Epoch 356: error is 6.26074198361293\n",
      "Epoch 357: error is 3.0837700756377373\n",
      "Epoch 358: error is 4.940844721007994\n",
      "Epoch 359: error is 4.433421656931612\n",
      "Epoch 360: error is 3.9432696046334827\n",
      "Epoch 361: error is 3.918876129078308\n",
      "Epoch 362: error is 4.911715104744165\n",
      "Epoch 363: error is 4.390573404771598\n",
      "Epoch 364: error is 3.6841590850730332\n",
      "Epoch 365: error is 5.67042675227777\n",
      "Epoch 366: error is 2.8843253323128546\n",
      "Epoch 367: error is 3.5857617305481373\n",
      "Epoch 368: error is 3.8979091481433987\n",
      "Epoch 369: error is 2.821466914297078\n",
      "Epoch 370: error is 3.6153362845004806\n",
      "Epoch 371: error is 3.5782693403129078\n",
      "Epoch 372: error is 4.043642495414426\n",
      "Epoch 373: error is 3.2883518118508896\n",
      "Epoch 374: error is 4.496658387770932\n",
      "Epoch 375: error is 3.8158534192264417\n",
      "Epoch 376: error is 2.3976683692369636\n",
      "Epoch 377: error is 3.9047180265231582\n",
      "Epoch 378: error is 5.047423131135898\n",
      "Epoch 379: error is 2.902045057948421\n",
      "Epoch 380: error is 3.1962453850519874\n",
      "Epoch 381: error is 4.181454895255546\n",
      "Epoch 382: error is 2.288411499317265\n",
      "Epoch 383: error is 3.1554150913871823\n",
      "Epoch 384: error is 2.2477894146949002\n",
      "Epoch 385: error is 3.2143554934932914\n",
      "Epoch 386: error is 3.834056770296478\n",
      "Epoch 387: error is 2.7866438566612373\n",
      "Epoch 388: error is 3.331462361035688\n",
      "Epoch 389: error is 3.1561878074011793\n",
      "Epoch 390: error is 3.299220867370082\n",
      "Epoch 391: error is 2.1082356766813937\n",
      "Epoch 392: error is 3.0428060578498384\n",
      "Epoch 393: error is 3.0663994393963008\n",
      "Epoch 394: error is 2.4485224980955063\n",
      "Epoch 395: error is 4.0082761468585915\n",
      "Epoch 396: error is 4.108469727522465\n",
      "Epoch 397: error is 2.4292596978627494\n",
      "Epoch 398: error is 3.117982145853236\n",
      "Epoch 399: error is 2.418867022149868\n",
      "Epoch 400: error is 4.590631105787774\n",
      "Epoch 401: error is 2.0097603722629973\n",
      "Epoch 402: error is 3.5032452914849257\n",
      "Epoch 403: error is 1.980529697560657\n",
      "Epoch 404: error is 3.3460565859305067\n",
      "Epoch 405: error is 2.847639497368738\n",
      "Epoch 406: error is 2.5841572287851453\n",
      "Epoch 407: error is 1.8674817725010553\n",
      "Epoch 408: error is 4.125384354101524\n",
      "Epoch 409: error is 2.335166179835461\n",
      "Epoch 410: error is 2.2111125264185367\n",
      "Epoch 411: error is 1.819699411288615\n",
      "Epoch 412: error is 2.8980091094020577\n",
      "Epoch 413: error is 3.1271071570963644\n",
      "Epoch 414: error is 1.769510877957394\n",
      "Epoch 415: error is 1.8447934782446012\n",
      "Epoch 416: error is 3.484024763365888\n",
      "Epoch 417: error is 2.491173823261366\n",
      "Epoch 418: error is 2.4844823960528313\n",
      "Epoch 419: error is 2.887340198368112\n",
      "Epoch 420: error is 2.4742286067340893\n",
      "Epoch 421: error is 3.0829787406068614\n",
      "Epoch 422: error is 1.6820440559844827\n",
      "Epoch 423: error is 2.3540677901043576\n",
      "Epoch 424: error is 1.7687440765849927\n",
      "Epoch 425: error is 2.7988316234038733\n",
      "Epoch 426: error is 2.8599639670623853\n",
      "Epoch 427: error is 2.7857705781175928\n",
      "Epoch 428: error is 2.3401272963685393\n",
      "Epoch 429: error is 3.095664329086453\n",
      "Epoch 430: error is 2.98252272200863\n",
      "Epoch 431: error is 3.1322102689388163\n",
      "Epoch 432: error is 2.7610394083840397\n",
      "Epoch 433: error is 2.6410990604222357\n",
      "Epoch 434: error is 1.9800528584366617\n",
      "Epoch 435: error is 1.6870755165084996\n",
      "Epoch 436: error is 4.054227759534111\n",
      "Epoch 437: error is 1.6719841305384866\n",
      "Epoch 438: error is 2.0862532221576675\n",
      "Epoch 439: error is 1.5552986279278318\n",
      "Epoch 440: error is 1.5462822940012084\n",
      "Epoch 441: error is 1.6510634988281956\n",
      "Epoch 442: error is 1.5343508928780583\n",
      "Epoch 443: error is 2.0212930985737807\n",
      "Epoch 444: error is 1.6357397138696634\n",
      "Epoch 445: error is 1.5242593722830782\n",
      "Epoch 446: error is 3.1658288413692652\n",
      "Epoch 447: error is 1.967739531434361\n",
      "Epoch 448: error is 1.5258017412799758\n",
      "Epoch 449: error is 1.6120740933508368\n",
      "Epoch 450: error is 1.5140021940092472\n",
      "Epoch 451: error is 2.3961075548958606\n",
      "Epoch 452: error is 1.496253222403998\n",
      "Epoch 453: error is 1.8400766852205823\n",
      "Epoch 454: error is 1.484236425531242\n",
      "Epoch 455: error is 1.9394413887467044\n",
      "Epoch 456: error is 1.584674484120015\n",
      "Epoch 457: error is 1.9155176571948964\n",
      "Epoch 458: error is 1.5768132343853825\n",
      "Epoch 459: error is 1.7974100992436435\n",
      "Epoch 460: error is 3.4181935504994447\n",
      "Epoch 461: error is 1.566637982614985\n",
      "Epoch 462: error is 1.8995333425080425\n",
      "Epoch 463: error is 2.2775103622973343\n",
      "Epoch 464: error is 2.922840999402492\n",
      "Epoch 465: error is 1.553072281169885\n",
      "Epoch 466: error is 2.2447714201695232\n",
      "Epoch 467: error is 1.4125652073319113\n",
      "Epoch 468: error is 2.2141737469471345\n",
      "Epoch 469: error is 2.8108335736634347\n",
      "Epoch 470: error is 1.390584942359524\n",
      "Epoch 471: error is 1.3837290144107905\n",
      "Epoch 472: error is 1.5373623762379474\n",
      "Epoch 473: error is 2.0672605050659265\n",
      "Epoch 474: error is 2.623919365032403\n",
      "Epoch 475: error is 3.0369452096548617\n",
      "Epoch 476: error is 1.5208625523948398\n",
      "Epoch 477: error is 1.5185995183030758\n",
      "Epoch 478: error is 1.8558474859355778\n",
      "Epoch 479: error is 1.5128401446302893\n",
      "Epoch 480: error is 1.380016280750653\n",
      "Epoch 481: error is 1.5092170953162423\n",
      "Epoch 482: error is 1.5071994939626803\n",
      "Epoch 483: error is 1.5052300886101073\n",
      "Epoch 484: error is 1.3710518004077106\n",
      "Epoch 485: error is 1.5018791093011556\n",
      "Epoch 486: error is 1.499998055761888\n",
      "Epoch 487: error is 1.49816104161391\n",
      "Epoch 488: error is 1.4963664855483834\n",
      "Epoch 489: error is 1.4946128721031031\n",
      "Epoch 490: error is 1.3618662604837517\n",
      "Epoch 491: error is 1.4916135456175983\n",
      "Epoch 492: error is 1.4899316091715111\n",
      "Epoch 493: error is 1.4882874220174735\n",
      "Epoch 494: error is 1.3537540228097025\n",
      "Epoch 495: error is 1.3463978546013349\n",
      "Epoch 496: error is 1.3392372001620536\n",
      "Epoch 497: error is 1.4833237676122524\n",
      "Epoch 498: error is 1.4817213876474653\n",
      "Epoch 499: error is 1.4801562231808802\n",
      "[[ 1.73691849  0.03151434  0.12837775]\n",
      " [ 0.59689358 -2.88627411  1.60745706]\n",
      " [-0.02779749 -2.74344392  0.65316544]\n",
      " [ 3.22613864  1.13539787  1.16522529]\n",
      " [ 0.12986299  2.25587686 -2.15780549]\n",
      " [-0.37358753  1.19409771 -2.2990044 ]\n",
      " [-2.3928751  -1.71585657 -1.72630697]]\n",
      "[[1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  r = RBM(num_visible = 6, num_hidden = 2)\n",
    "  training_data = np.array([[1,1,1,0,0,0],[1,0,1,0,0,0],[1,1,1,0,0,0],[0,0,1,1,1,0], [0,0,1,1,0,0],[0,0,1,1,1,0]])\n",
    "  r.train(training_data, max_epochs = 500)\n",
    "  print(r.weights)\n",
    "  user = np.array([[0,0,0,1,1,0]])\n",
    "  print(r.run_visible(user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
